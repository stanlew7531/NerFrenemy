{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4375d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.insert(1, './PoseCNN-PyTorch/lib')\n",
    "from datasets.factory import get_dataset\n",
    "from fcn.config import cfg, cfg_from_file, yaml_from_file, get_output_dir\n",
    "from fcn.test_imageset import test_image\n",
    "from ycb_renderer import YCBRenderer\n",
    "from get_available_devices import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.parallel \n",
    "import torch.backends.cudnn as cudnn \n",
    "import networks\n",
    "from utils.nms import *\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [18, 9]\n",
    "from utils.blob import pad_im, chromatic_transform, add_noise\n",
    "from transforms3d.quaternions import mat2quat, quat2mat\n",
    "from utils.se3 import *\n",
    "from utils.pose_error import *\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from ProgressNerf.Dataloading.YCBVideoDataloader import YCBVideoDataloader\n",
    "# import ProgressNerf.Dataloading.ToolsPartsDataloader\n",
    "\n",
    "import ProgressNerf.Raycasting.VoxelGridBBoxRaysampler\n",
    "import ProgressNerf.Raycasting.RandomRaypicker\n",
    "import ProgressNerf.Raycasting.NearFarRaysampler\n",
    "import ProgressNerf.Raycasting.WeightedRaypicker\n",
    "import ProgressNerf.Raycasting.PerturbedRaysampler\n",
    "\n",
    "import ProgressNerf.NeuralRendering.NeuralRenderer\n",
    "# import ProgressNerf.NeuralRendering.VoxelNeuralRenderer\n",
    "\n",
    "import ProgressNerf.Encoders.PositionalEncoder\n",
    "\n",
    "# import ProgressNerf.Models.OGNerf\n",
    "# from ProgressNerf.Architectures.OGNerfArch import OGNerfArch\n",
    "import ProgressNerf.Models.FastNerf\n",
    "from ProgressNerf.Architectures.VoxelGridCachedNerf import VoxelGridCachedNerf\n",
    "\n",
    "from ProgressNerf.Utils.CameraUtils import BuildCameraMatrix\n",
    "from fcn.train import loss_cross_entropy, smooth_l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ac3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb00c8",
   "metadata": {},
   "source": [
    "# Setup Dataloader & Metadata for PoseCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41fc1133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: DRI2: failed to create dri screen\n",
      "libEGL warning: DRI2: failed to create dri screen\n",
      "Unable to initialize EGL\n",
      "libEGL warning: DRI2: failed to create dri screen\n",
      "libEGL warning: DRI2: failed to create dri screen\n",
      "Unable to initialize EGL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of devices found 5\n",
      "Loaded EGL 1.5 after reload.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "cfg_from_file(\"./PoseCNN-PyTorch/experiments/cfgs/ycb_object.yml\")\n",
    "meta = yaml_from_file(\"./PoseCNN-PyTorch/data/demo/meta.yml\")\n",
    "dataset = get_dataset(\"ycb_object_test\")\n",
    "cfg.renderer = YCBRenderer(width=cfg.TRAIN.SYN_WIDTH, height=cfg.TRAIN.SYN_HEIGHT, gpu_id=0, render_marker=False)\n",
    "\n",
    "worker_init_fn = dataset.worker_init_fn if hasattr(dataset, 'worker_init_fn') else None\n",
    "num_workers = 0 if cfg.TRAIN.SYNTHESIZE else 4\n",
    "dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                    batch_size=1,  #cfg.TRAIN.IMS_PER_BATCH, \n",
    "                    shuffle=True, \n",
    "                    num_workers=num_workers, \n",
    "                    worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ae9dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if cfg.TEST.SYNTHESIZE:\n",
    "    cfg.renderer.load_objects(dataset.model_mesh_paths, dataset.model_texture_paths, dataset.model_colors)\n",
    "else:\n",
    "    model_mesh_paths = [dataset.model_mesh_paths[i-1] for i in cfg.TEST.CLASSES[1:]]\n",
    "    model_texture_paths = [dataset.model_texture_paths[i-1] for i in cfg.TEST.CLASSES[1:]]\n",
    "    model_colors = [dataset.model_colors[i-1] for i in cfg.TEST.CLASSES[1:]]\n",
    "    cfg.renderer.load_objects(model_mesh_paths, model_texture_paths, model_colors)\n",
    "\n",
    "cfg.renderer.set_camera_default()\n",
    "cfg.TEST.POSE_REFINE = False\n",
    "cfg.TEST.VISUALIZE = False \n",
    "cfg.TRAIN.VERTEX_REG = True\n",
    "cfg.TRAIN.POSE_REG = True\n",
    "\n",
    "cfg.MODE = 'TEST'\n",
    "\n",
    "cfg.gpu_id = 0\n",
    "cfg.device = torch.device('cuda:{:d}'.format(cfg.gpu_id))\n",
    "cfg.instance_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c6c938",
   "metadata": {},
   "source": [
    "# Setup Dataloader for our optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5afd474",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = { \"baseDataDir\": \"/home/stanlew/data/ycb-video/tool-parts_dataset/\",\\\n",
    "               \"scenes\": [\"0036\",\"0037\",\"0044\",\"0060\",\"0066\",\"0068\",\"0076\",\"0079\",\"0087\",\"0089\"],\\\n",
    "               \"datasetType\": \"train\",\\\n",
    "               \"samplesLimit\": -1,\\\n",
    "               \"rel_tools\": [\"04\"]}\n",
    "progNerfDataloader = torch.utils.data.DataLoader(YCBVideoDataloader(config_dict),\\\n",
    "                                                 batch_size = 1,\\\n",
    "                                                 shuffle=True,\\\n",
    "                                                 num_workers = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d2392d",
   "metadata": {},
   "source": [
    "# Load PoseCNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bfd87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pretrained = \"./PoseCNN-PyTorch/data/checkpoints/ycb_object/vgg16_ycb_object_self_supervision_epoch_8.checkpoint.pth\"\n",
    "\n",
    "cfg.TRAIN.FREEZE_LAYERS = False\n",
    "num_classes = dataset.num_classes\n",
    "gpu_id = 1\n",
    "network_data = torch.load(pretrained, map_location = \"cpu\")\n",
    "network = networks.__dict__[\"posecnn\"](num_classes, 64, network_data).to(cfg.device)\n",
    "network = torch.nn.DataParallel(network, device_ids=[cfg.gpu_id]).to(cfg.device)\n",
    "cudnn.benchmark = True\n",
    "network.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3886789",
   "metadata": {},
   "source": [
    "# Setup NeRF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "490ebee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading config at ./ycbVideo_Soup.yml\n",
      "parsing config\n",
      "initializing optimizer\n",
      "loading model  & optimizer params from /home/stanlew/Documents/ProgressNerfModels/ycb_video/soup_can_6/epoch_200\n",
      "resuming training from epoch 201...\n"
     ]
    }
   ],
   "source": [
    "config_file = \"./ycbVideo_Soup.yml\"\n",
    "arch = VoxelGridCachedNerf(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e52d26e",
   "metadata": {},
   "source": [
    "# Loop Over Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb613887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVisualizedImg(sample_img):\n",
    "    return (sample_img[0].permute(1,2,0) + 1.0 / 2.0).cpu().numpy()\n",
    "\n",
    "def run_net(network, dataset, im_color, device):\n",
    "    im_color.to(device)\n",
    "    \n",
    "    K = dataset._intrinsic_matrix\n",
    "    K[2, 2] = 1\n",
    "    Kinv = np.linalg.pinv(K)\n",
    "    meta_data = np.zeros((1, 18), dtype=np.float32)\n",
    "    meta_data[0, 0:9] = K.flatten()\n",
    "    meta_data[0, 9:18] = Kinv.flatten()\n",
    "    meta_data = torch.from_numpy(meta_data).to(device).contiguous()\n",
    "    \n",
    "    out_prob, out_label, out_vertex, rois, out_pose, out_quaternion =\\\n",
    "        network(im_color, dataset.input_labels.contiguous(), meta_data, \\\n",
    "            dataset.input_extents.contiguous(), dataset.input_gt_boxes.contiguous(),\\\n",
    "            dataset.input_poses.contiguous(), dataset.input_points.contiguous(),\\\n",
    "            dataset.input_symmetry.contiguous())\n",
    "    \n",
    "    return out_prob, out_label, out_vertex, rois, out_pose, out_quaternion\n",
    "\n",
    "def get_depth_rgb_from_render(render_result, num_cameras, width, height):\n",
    "    rgb_output = render_result['rgb']\\\n",
    "        .reshape((num_cameras, width, height, 3)).transpose(1,2).contiguous()\n",
    "    depth_output = render_result['depth']\\\n",
    "        .reshape((num_cameras, width, height, 1)).transpose(1,2).contiguous()\n",
    "    return rgb_output, depth_output\n",
    "\n",
    "def sample_on_cylinder(height_mm=100, radius_mm=33):\n",
    "    samples = []\n",
    "    theta = 0\n",
    "    z_inc = 0.5\n",
    "    z = -height_mm/2\n",
    "    # sample points in cylinder frame\n",
    "    while z < height_mm/2:\n",
    "        while theta < 2 * np.pi:\n",
    "            x = radius_mm * np.cos(theta)\n",
    "            y = radius_mm * np.sin(theta)\n",
    "            point = np.array([x, y, z])\n",
    "            samples.append(point)\n",
    "            theta += np.pi/6\n",
    "        theta = 0\n",
    "        z+=z_inc\n",
    "    return samples\n",
    "\n",
    "def sample_from_voxel_grid(grid):\n",
    "    positive_values = grid.voxels[(grid.voxels[...,-1:].relu() > 0).squeeze()]\n",
    "    return positive_values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47017a28",
   "metadata": {},
   "source": [
    "fig, axs = plt.subplots(1,3)\n",
    "for batch_ndx, sample in enumerate(iter(dataloader)):\n",
    "    #dict_keys(['image_color', 'im_depth', 'label', 'mask', 'meta_data', 'poses', 'extents', 'points', 'symmetry', 'gt_boxes', 'im_info', 'video_id', 'image_id', 'vertex_targets', 'vertex_weights'])\n",
    "    image_color = sample['image_color'].to(cfg.device)\n",
    "    print(image_color.shape)\n",
    "    image_depth = sample['im_depth'].to(cfg.device)\n",
    "    metadata = sample['meta_data'].to(cfg.device)\n",
    "    \n",
    "    axs[0].imshow(getVisualizedImg(image_color)[:,:,::-1])\n",
    "    \n",
    "    pcnn_prob, pcnn_label, pcnn_vertex, pcnn_rois, pcnn_pose, pcnn_quaternion =\\\n",
    "        run_net(network, dataset, image_color, cfg.device)\n",
    "    \n",
    "    axs[1].imshow(pcnn_label.cpu().numpy()[0])\n",
    "    axs[2].imshow(pcnn_label.cpu().numpy()[0] == 4)\n",
    "    \n",
    "    raise Exception(\"stopping to print\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c159963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the UVW (*not* s) parameters that correspond to the can's geometry\n",
    "    # get the xyz locations from the Can sampler\n",
    "can_samples = torch.from_numpy(np.array(sample_on_cylinder())).to(cfg.device) / 1000.0 # convert to meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7428e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the voxel cache from the architecture\n",
    "uvws_cache = arch.uvws_cache\n",
    "uvws_cache.voxels.requires_grad = True\n",
    "# get the voxel data that correspond to the sampled points\n",
    "#uvws = uvws_cache.get_voxels_xyz(can_samples)\n",
    "#sigmas = uvws[...,-1:]\n",
    "params = [uvws_cache.voxels]#[uvws_cache.voxels[...,-1:]]#[sample_from_voxel_grid(uvws_cache)[...,:-1]] # only add the uvw to the optimization parameters - we dont want to perturb sigma\n",
    "# create optimizer\n",
    "optimizer = torch.optim.Adam(params, lr=0.0075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "402670a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NerfRenderSegLoss(inferred_probs, gt_mask):\n",
    "    return torch.sum(1.0 - (inferred_probs[0,4] * gt_mask[0])) / torch.sum(gt_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b67aa915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBack(var_grad_fn, level=0):\n",
    "    for _ in range(level):\n",
    "        print(\".\", end = '')\n",
    "    print(var_grad_fn)\n",
    "    for n in var_grad_fn.next_functions:\n",
    "        if n[0]:\n",
    "            try:\n",
    "                tensor = getattr(n[0], 'variable')\n",
    "                print(n[0])\n",
    "                print('Tensor with grad found:', tensor)\n",
    "                print(' - gradient:', tensor.grad)\n",
    "                print()\n",
    "            except AttributeError as e:\n",
    "                getBack(n[0], level+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df59f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanlew/anaconda3/envs/nerfrenemy/lib/python3.8/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.6826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.2846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.6964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.6310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.4357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.3336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.2082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.4977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.2940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.1643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.7220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.7077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.9807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.4858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.9674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.3777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.5391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.6773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.0273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.6632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.1831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.7736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.9646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.9090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.6593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.5058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(1.4463, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(4,2)  \n",
    "showFigs = False\n",
    "arch.raypicker.num_rays = 10000\n",
    "for batch_ndx, sample in enumerate(iter(progNerfDataloader)):\n",
    "    #print(sample.keys())\n",
    "    gt_seg = sample['segmentation'].to(cfg.device)\n",
    "    image_color = sample['image'].to(cfg.device).permute((0,3,1,2)).contiguous()\n",
    "    \n",
    "    # get the weighting matrix for sampling pixels\n",
    "    weighting_seg = (gt_seg[0] == 4) * 1.0\n",
    "    weighting_seg = weighting_seg / torch.sum(weighting_seg)\n",
    "    cam_pose = torch.eye(4, device=cfg.device).unsqueeze(0)\n",
    "    ray_origins, ray_dirs, ijs =\\\n",
    "        arch.raypicker.getRays(cam_pose, ray_weights = weighting_seg.repeat(cam_pose.shape[0],1,1))\n",
    "    \n",
    "    if showFigs:\n",
    "        axs[0, 0].imshow(sample['image'][0].cpu().numpy())\n",
    "        axs[0, 1].imshow(sample['segmentation'][0].cpu().numpy() == 4)\n",
    "        \n",
    "    #print(image_color.shape)\n",
    "    with torch.no_grad():\n",
    "        pcnn_prob, pcnn_label, pcnn_vertex, pcnn_rois, pcnn_pose, pcnn_quaternion =\\\n",
    "            run_net(network, dataset, image_color, cfg.device)\n",
    "\n",
    "        #print(pcnn_rois)\n",
    "        index = torch.where(pcnn_rois[:, -1] > cfg.TEST.DET_THRESHOLD)[0]\n",
    "        #print(index)\n",
    "        if showFigs:\n",
    "            axs[1, 0].imshow(pcnn_label.cpu().numpy()[0])\n",
    "            axs[1, 1].imshow(pcnn_label.cpu().numpy()[0] == 4)\n",
    "        for j in range(pcnn_rois.shape[0]):\n",
    "            pcnn_rois[j, 1] = cfg.TRAIN.CLASSES.index(cfg.TEST.CLASSES[int(pcnn_rois[j,1])])\n",
    "    \n",
    "    # render arch at pose from sample\n",
    "    sample_pose = torch.linalg.inv(sample['04_pose'])\n",
    "    render_result = arch.render(ray_origins, ray_dirs, use_cache = True)\n",
    "    \n",
    "    #render_result = arch.doFullRender(sample_pose, use_cache = True)\n",
    "    #render_result['rgb'].requires_grad = True\n",
    "    render_result['rgb'].retain_grad()\n",
    "    #nerf_rgb, nerf_depth = get_depth_rgb_from_render(render_result, 1, 640, 480)\n",
    "    #nerf_rgb.requires_grad = True\n",
    "    #nerf_rgb.retain_grad()\n",
    "    # overlay the nerf_rgb into the scene\n",
    "    overlayed = image_color.permute(0,2,3,1).clone()\n",
    "    #print(overlayed.shape)\n",
    "    #overlayed[0, (sample['segmentation'][0].cpu().numpy() == 4), ...] =\\\n",
    "        #nerf_rgb[0, (sample['segmentation'][0].cpu().numpy() == 4), ...]\n",
    "\n",
    "    for i in range(render_result['rgb_alpha'][0].shape[0]):\n",
    "        overlayed[0, ijs[0,i,1], ijs[0,i,0], :] = render_result['rgb_alpha'][0,i]\n",
    "        #gt_pixels[i] = gt_pixels[i] + segmented_gt[0, ijs[i,:,1], ijs[i,:,0], :]\n",
    "        #gt_depths[i] = gt_depths[i] + seg_depth_gt[0, ijs[i,:,1], ijs[i,:,0]]\n",
    "    \n",
    "    if showFigs:\n",
    "        #axs[2, 0].imshow(nerf_rgb.cpu().detach().numpy()[0])\n",
    "        axs[2, 1].imshow(overlayed.cpu().detach().numpy()[0])\n",
    "    \n",
    "    # run poseCNN on the updated scene\n",
    "    overlayed = overlayed.permute(0,3,1,2)\n",
    "    \n",
    "    #overlayed.requires_grad = True\n",
    "    #network.requires_grad = True\n",
    "    overlayed.retain_grad()\n",
    "    pcnn_prob, pcnn_label, pcnn_vertex, pcnn_rois, pcnn_pose, pcnn_quaternion =\\\n",
    "        run_net(network, dataset, overlayed, cfg.device)\n",
    "\n",
    "    if showFigs:\n",
    "        axs[3, 0].imshow(pcnn_label.cpu().numpy()[0])\n",
    "        #axs[3, 1].imshow(pcnn_label.cpu().numpy()[0] == 4)\n",
    "        axs[3, 1].imshow(pcnn_prob[0,4].cpu().detach().numpy())\n",
    "        \n",
    "    #print(params[0].grad)\n",
    "    pcnn_prob.retain_grad()\n",
    "    loss = NerfRenderSegLoss(pcnn_prob, gt_seg == 4)\n",
    "    print(loss)\n",
    "    loss.backward(retain_graph=True)\n",
    "    #print(loss.grad)\n",
    "    #print(params[0])\n",
    "    #print(uvws_cache.voxels.grad.unique())\n",
    "    #print(pcnn_prob.grad.shape)\n",
    "    #print(overlayed.grad.unique())\n",
    "    #print(nerf_rgb.grad.unique())\n",
    "    #print(render_result['rgb'].grad.unique())\n",
    "    #getBack(loss.grad_fn)\n",
    "    #nerf_rgb.grad\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if showFigs:\n",
    "        raise Exception(\"stopping to print\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399389bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nerfrenemy)",
   "language": "python",
   "name": "nerfrenemy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
